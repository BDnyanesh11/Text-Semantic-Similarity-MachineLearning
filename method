The NLTK module is a massive tool kit, aimed at helping you with the entire Natural Language Processing (NLP) methodology. NLTK will aid you with everything from splitting sentences from paragraphs, splitting up words, recognizing the part of speech of those words, highlighting the main subjects, and then even with helping your machine to understand what the text is all about.
Corpus - Body of text, singular. Corpora is the plural of this. Example: A collection of medical journals.

Lexicon - Words and their meanings. Example: English dictionary. Consider, however, that various fields will have different lexicons. For example: To a financial investor, the first meaning for the word "Bull" is someone who is confident about the market, as compared to the common English lexicon, where the first meaning for the word "Bull" is an animal. As such, there is a special lexicon for financial investors, doctors, children, mechanics, and so on.

Tokenizing - Splitting sentences and words from the body of text. Tokenzing are of two types sentence tokeninzing and word tokenizing
word tokenizing - separates every word in a sentence. Words are separated by space after the word, i.e.,after every word there is a space. It counts punctuation as a separate token/word (,.!?etc)
Currently, we have done it only for one sentence and not implemented sentence tokenizing yet.  

Token - Each "entity" that is a part of whatever was split up based on rules. For examples, each word is a token when a sentence is "tokenized" into words. Each sentence can also be a token, if you tokenized the sentences out of a paragraph.

Corpus - Body of text, singular. Corpora is the plural of this. Example: A collection of medical journals.

Lexicon - Words and their meanings. Example: English dictionary. Consider, however, that various fields will have different lexicons. For example: To a financial investor, the first meaning for the word "Bull" is someone who is confident about the market, as compared to the common English lexicon, where the first meaning for the word "Bull" is an animal. As such, there is a special lexicon for financial investors, doctors, children, mechanics, and so on.

Stop words - Sometimes, some extremely common words which would appear to be of little value in helping select documents matching a user need are excluded from the vocabulary entirely. These words are called stop words . The general strategy for determining a stop list is to sort the terms by collection frequency (the total number of times each term appears in the document collection), and then to take the most frequent terms, often hand-filtered for their semantic content relative to the domain of the documents being indexed, as a stop list , the members of which are then discarded during indexing. An example of stop list is shown in the figure. Using a stop list significantly reduces the number of postings that a system has to store. Stop words can be filtered from the text to be processed. There is no universal list of stop words in nlp, however the nltk module contains a list of stop words. We then remove the stop words from the sentence.

Lemmatizing - The goal of lemmatization is to reduce inflectional forms and sometimes derivationally related forms of a word to a common base form.  Lemmatization usually refers to doing things properly with the use of a vocabulary and morphological analysis of words, normally aiming to remove inflectional endings only and to return the base or dictionary form of a word, which is known as the lemma . Lemmas create actual words. If confronted with the token 'saw' lemmatization would attempt to return either see or saw depending on whether the use of the token was as a verb or a noun. Lemmatization commonly only collapses the different inflectional forms of a lemma. So, your root stem, meaning the word you end up with, is not something you can just look up in a dictionary, but you can look up a lemma. The only major thing to note is that lemmatize takes a part of speech parameter, "pos." If not supplied, the default is "noun." This means that an attempt will be made to find the closest noun of that word. 

Synset - WordNet is a lexical database for the English language, and is part of the NLTK corpus. We can use WordNet alongside the NLTK module to find the meaning of words, synonyms, antonyms and more.  Synonyms are word that have similar meaning, therefore a synonym set or synset, is a group of synonyms. The lemmas will be synonyms, and then we can use .antonyms to find the antonyms to the lemmas. Next, we can also easily use WordNet to compare the similarity of two words and their tenses, by incorporating the Wu and Palmer method for semantic related-ness.
